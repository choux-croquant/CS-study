## [가상 메모리 #1](https://core.ewha.ac.kr/publicview/C0101020140509142939477563?vmode=f)

### Demand Paging

- 실제로 필요한 때 page를 메모리에 올리는 방법을 의미
  - I/O양이 상당 부분 감소
  - Memory사용량 감소
  - 빠른 응답 시간
  - 더 많은 사용자 수용(멀티 프로그래밍 환경)
- Valid/Invalid bit의 사용
  - Invalid - 사용되지 않는 주소 영역이거나, 페이가 물리적 메모리에 없는 경우
  - 처음에는 모든 page entry가 Invalid로 초기화된다.
  - address translation시 Invalid bit가 설정되어 있다면 > page fault(요청한 페이지가 메모리에 없는 경우)

### Page Fault

- Invalid page접근 시 MMU가 trap을 발생시킨다.(page fault trap)

- Kernel mode로 들어가서 page fault handler가 invoke된다.

- 다음의 루틴으로 page fault를 처리한다.

  - Invalid reference? (bad address, protection violation ...) > abort process
  - Get an empty page frame (빈 프레임이 없다면 뺏어옴 - replace)
  - 해당 페이지를 디스크에서 메모리로 읽어온다.
    - Disk I/O가 끝나기까지 이 프로세스는 CPU를 preempt당한다.(block)
    - Disk read가 끝나면 page tables entry기록, valid bit = "valid"
    - Ready queue에 process를 insert > dispatch later
  - 프로세스가 CPU를 잡고 다시 running
  - 아까 중단되었던 instruction을 재개한다.

  ![Page Fault Handling in Operating System - javatpoint](https://static.javatpoint.com/operating-system/images/page-fault-handling-in-operating-system.png)

- Performance of Demand Paging

  - Page fault가 일어나는 비율에 따라 효율이 좌우된다..
  - Page fault rate - 0 <= p <= 1.0
  - 0이면 page fault가 없고, 1이면 모든 참조가 fault인 상태
  - 일반적으로 page fault rate은 매우 낮음
  - Effective Access Time
    - EAT = (1 - p) * memory access + p(OS & HW page fault overhead + [swap page out if needed] + swap page in + OS & HW restart overhead)
    - fault가 일어날 때마다 OS & HW에서 처리하는 오버헤드와 swap작업 등 엄청난 시간이 소요

### Optimal Algorithm

- MIN(OPT) - 가장 먼 미래에 참조되는 page를 replace하는 방법
- 미래에 일어날 참조를 아는 방법? > 당연히 모른다! 실제로 적용할 수 없음
- 다른 알고리즘에 대한 upper bound를 제공하는 역할을 할 수 있다.

### FIFO(First In First Out) Algorithm

- replace시 가장 먼저 들어온 것을 선택하는 방식

### LRU(Least Recently Used) Algorithm

- 가장 오래전에 참조된 것을 replace하는 방식

### LFU(Least Frequently Used) Algorithm

- 가장 참조된 빈도가 적은 것을 repalce하는 방식
- 최저 참조 횟수인 page가 여러개인 경우
  - 임의로 선정하거나 가장 LRU방식을 섞어 가장 오래된 것을 지우도록 할 수도 있다.
- LRU처럼 직전 참조 시점만 보는 게 아니라 장기적 시간 규모를 보기 때문에 page의 인기도를 보다 정확히 반영 가능
- 반면, 참조 시점의 최근성은 반영하지 못한다.
- LRU방식 보다 구현히 어렵다.

### LRU와 LFU 알고리즘의 예제 및 구현

- LRU - Linked list를 사용하여 구현하면 O(1) 복잡도로 구현할 수 있다.
  - 새로운 참조를 가장 위로 올리고, replace시 가장 뒤쪽를 보내면 된다.
- LFU - Linked list로 구현 시 참조할 때마다 각 노드의 참조된 횟수를 알아야 하므로 O(n)의 복잡도로 구현된다.
- LFU를 참조횟수가 가장 적은 page가 root인 heap으로 구현 시 O(logn)으로 구현할 수 있다.

## [가상 메모리 #2](https://core.ewha.ac.kr/publicview/C0101020140513133424380501?vmode=f)

### 다양한 캐싱 환경

- 캐싱 기법
  - 한정된 빠른 공간(=캐시)에 요청된 데이터를 저장해 두었다가 후속 요청 시 캐시로부터 직접 데이터를 서비스하는 방식
  - paging system이외에도 cache memory, buffer caching, web caching등 다양한 분야에 사용되는 기법
- 캐시 운영의 시간 제약
  - 교체 알고리즘에서 삭제할 항목을 결정하는 일에 지나치게 많은 시간이 걸리는 경우 실제 시스템에서 사용할 수 없다.
  - Buffer caching, web caching의 경우 - O(1)에서 O(logn)정도까지 허용한다.
  - Paging system인 경우
    - page fault인 경우에만 OS가 관여
    - 페이지가 이미 메모리에 존재하는 경우 참조 시작 등의 정보를 OS가 알 수 없다.
    - O(1)인 LRU의 list 조작 불가능

### Clock Algorithm

- LRU의 근사(approximation) 알고리즘, Second chance algorithm or NUR(Not Used Recently) 등으로도 불린다.
  - Reference bit을 사용해서 교체 대상 페이지를 선정한다. (circular list)
  - Reference bit이 0인 것을 찾을 때까지 포인터를 하나씩 앞으로 이동한다.
  - 포인터가 이동하는 중에 reference bit이 1이면 모두 0으로 바꾼다.
  - Reference bit이 0인 것을 찾으면 그 페이지를 교체한다.
  - 한 바퀴를 돌고 나서도(=second chance) 0이면 그 때에는 replace당한다.
  - 자주 사용되는 페이지라면 second chance가 올 때 1
- Clock alogorithm 개선하기
  - Reference bit과 Modified bit(dirty bit)을 함께 사용한다.
  - Reference bit = 1 : 최근에 참조된 페이지
  - Modified bit = 1 : 최근에 변경된 페이지(I/O를 동반하는 페이지)
  - (Reference bit, Modified bit)이라고 하면 각각의 케이스에 따라 작업 
    - (0, 0) - 해당 페이지 교체, 포인터 이동 후 선정 종료
    - (0, 1) - (0, 0)으로 설정한 뒤 해당 페이지를 소거 대상 목록에 추가, 포인터 이동
    - (1, 0) - (0, 0)으로 설정한 뒤 포인터 이동 
    - (1, 1) - (0, 1)로 설정한 뒤 포인터 이동

### Page Frame의 Allocation

- Allocation problem - 각 프로세스에 얼마만큼의 page frame을 할당할 것인지에 대한 문제
- Allocation의 필요성
  - Allocation을 하지 않는다면 **특정 프로그램이 frame을 장악**할 경우 다른 프로그램이 올라올 때 **page fault가 빈번하게 발생**하게 될 수 있다.
  - 메모리 참조 명령어 수행 시 명령어, 데이터 등 여러 페이지를 동시에 참조하는 경우가 존재한다.
    - 명령어 수행을 위해 최소한으로 할당되어야 하는 frame의 수가 존재한다.
  - Loop를 구성하는 page들은 한꺼번에 allocate되는 것이 유리하다
    - 최소한의 allocation이 없다면, 매 loop마다 page fault가 일어나기 때문
- Allocation Scheme
  - Equal allocation - 모든 프로세스에 똑같은 개수의 프레임 할당하는 방식
  - Proportional allocation - 프로세스의 크기에 비례하여 할당하는 방식
  - Priority allocation - 프로세스의 우선순위에 따라 다르게 할당하는 방식

### Global vs. Local Replacement

- Global replacement
  - 미리 할당하지 않고 그때 그때 알고리즘에 따라 할당한다는 아이디어
  - Replace시 **다른 프로세스에 할당된 frame을 빼앗아** 올 수 있다.
  - 프로세스별 할당량을 조절하는 또 다른 방법
  - FIFO, LRU, LFU등 알고리즘을 global replacement로 사용 시에 해당한다.
  - Working set, PFF알고리즘 사용
- Local replacement
  - Allocation를 프로세스별로 진행한 뒤 **자신에게 할당된 frame내에서만** replace하는 방식
  - FIFO, LRU, LFU등 방식을 사용

### Thrashing

- 프로세스가 원활한 수행에 필요한 최소한의 page frame을 할당받지 못하여 page fault가 빈번하게 일어나는 상태를 의미한다. 너무 많은 프로그램이 올라가는 경우 Thrashing이 발생할 수 있음

- Thrashing이 발생하면

  - Page fault rate이 크게 높아진다.
  - CPU utilization이 낮아진다.
  - OS는 MPD(Multiprogramming degree)를 높여야 한다고 판단하게 된다. (CPU활용량이 적기 때문에)
  - 위의 판단으로 인해 또 다른 프로세스가 시스템에 추가
  - 프로세스가 추가되므로 프로세스당 할당된 frame수는 더욱 감소한다.
  - 할당된 frame이 부족하여 page fault가 빈번하게 일어나므로, page의 swap in / out 작업이 자주 일어나게 된다.
  - swap작업으로 인해 프로세스는 매우 바빠지지만 실제로 CPU는 활용이 거의 되지 않는 상태가 된다.
  - Throughput 이 급격하게 감소한다.
  - 아래 Diagram은 위의 과정을 표현하는 내용
  - ![Thrashing in Operating System – AHIRLABS](https://www.ahirlabs.com/wp-content/uploads/2018/08/ThrashingDiagram.png)

  

### Working-Set Model

- Locality of reference
  - 프로세스는 **특정 시간 동안에 일정 주소만**을 **집중적으로 참조**하는 특징을 가지는 경우가 많음
  - 집중적으로 참조되는 해당 page들의 집합을 locality set이라고 한다.
- Working-set model
  - Locality에 기반하여 프로세스가 일정 시간 동안 원활하게 수행되기 위해 한꺼번에 메모리에 올라와 있어야 하는 page들의 집합을 Working-set이라고 정의한다.
  - Working-set model에서는 프로세스의 working-set전체가 메모리에 올라와 있어야 수행되고, **그렇지 않은 경우 모든 frame을 반납**한 후 **swap out(suspend)**한다.
  - 위의 특정으로 인해 어느 정도 **Thrashing을 방지하는 효과**를 가진다.
  - **Multiprogramming degree를 조절**한다고도 할 수 있다.

### Working-Set Algorithm

- Working-set window를 통해 알아낸다.
- Window size가 d인 경우
  - 시각 t(i)에서의 working-set WS(t(i)) - Time interval [t(i) - d, t(i)]사이에 참조된 서로 다른 페이지들의 집합을 의미
  - Working-set에 속한 page는 메모리에 유지시키고, 속하지 않은 page는 버린다. = 참조된 후 d시간 동안 해당 page를 메모리에 유지한 후 버린다.
- Working-set algorithm
  - 프로세스들의 working-set size의 합이 page frame의 수보다 큰 경우
    - 일부 프로세스를 swap out시키고 남은 프로세스의 working-set을 우선적으로 충족시켜 준다. (MPD 감소)
  - Working-set을 다 할당하고도 page frame이 남는 경우
    - Swap out되었던 프로세스에게 working-set을 할당한다. (MPD 상승)
- Window size
  - Working-set을 제대로 탐지하기 위해서는 window size를 잘 결정해야 한다.
  - size가 너무 작으면 locality set을 모두 수용하지 못할 수 있음
  - size가 너무 크면 여러 규모의 locality set을 수용하게 됨
  - size가 무한이면 전체 프로그램을 구성하는 page를 working-set으로 간주하게 됨

### PFF(Page-Fault Frequency) Scheme

- Page fault rate의 상한과 하한을 두는 알고리즘
  - page fault rate이 상한을 넘으면 frame을 추가로 할당
  - page fault rate이 하한보다 낮으면 할당 frame을 줄인다.
- 빈 프레임이 없으면 일부 프로세스를 swap out한다.
- ![Operating Systems: Virtual Memory](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_21_PageFaultFrequency.jpg)

### Page Size의 결정

+ Page size를 감소시키는 경우
  + page의 수가 증가한다.
  + page table의 크기가 증가한다.
  + Internal fragmentation이 감소한다.
  + Disk transfer의 효율성이 감소한다.
    + Seek/rotation vs transfer
  + 필요한 정보만 메모리에 올라오기 때문에 메모리 이용이 효율적이다.
    + Locality의 활용 측면에서는 효율이 좋지 않을 수 있음
+ Trend
  + Larger page size